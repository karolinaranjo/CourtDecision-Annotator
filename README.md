# Automated Annotation of Court Decisions
## Colombian Constitutional Court

This repository hosts an automated system designed to process and classify decisionm documents from the Colombian Constitutional Court. It segments texts into specific sections (e.g., antecedentes, consideraciones de la corte, decision, etc.) and identifies text types (regular, quote, emphasis, footnote).

Using some of the functions developed for this endeavor, the user can do the following:

1) Convert RTF files to PDF format.
2) Convert a PDF file into an XML with tags denoting pages, paragraphs, and text blocks (with format information). The system has advanced capabilities to fix some errors related to parser interpretation of blank spaces
3) Create a local database of all font types (font name + size) used in a collection of documents.
4) Analyze a collection of PDF decision documents following the conventions used by the Colombian Constitutional Court and split them in paragraphs and text blocks, assigning to each a section
5) LLM-Based classification employs GPT-4, Llama-based, FlanT5 for text analysis, classifying paragraphs and text blocks into designated sections of judicial decision documents.

## How to Run

To run the full system, it is necessary to accomplish three tasks:

1) Convert PDF Files to Pandas DataFrames
   To process an entire folder, run the function `pdf_files_to_sau` found in `pdf_segmenter_utils.py`:

`paragraphs_df, styles_df, documents_df = pdf_segmenter_utils.pdf_files_to_sau(source_folder, target_folder, font_db_conn, paragraphs_df=None, styles_df=None)`

The function will return three Pandas dataframes ready for further processing.

2) Do the text analysis and assign sections

To assign sections to each row of the relevant dataframes, run the function `update_sections_all_documents(...)` found in `semantic_annotations_utils.py`:

`paragraphs_df, styles_df, documents_df=semantic_annotations_utils.update_sections_all_documents(paragraphs_df, styles_df, documents_df)`

3) Comparison the system annotations with LLM Outputs:

To compare the system annotations to those generated by LLMs, follow a multi-step process:

- Convert decision documents to JSON format Start including the section information. Use:

`out=llm_benchmarking_utils.pdf_files_to_json_for_section_identification_with_llms(pdf_folder, font_db_conn, df_format, df_docs, prompt)`

The code also includes functions for balancing data (`balance_data(...)`) and splitting the data into training, validation, and test sets (`split_json_data(...)`)

- Run experiments with GPT-4 and Llama 2b: `llm_benchmarking_utils.process_excerpts_with_gpt` and ``

- Experiments with
  
- Few-shot experiments: 

4) Few-shot and zero shot

## Files in the Repository:
`kutils.py`:  Contains various text processing functions.
`pdf_segmenter_utils.py`
`semantic_annotation_utils` : 
`llm_benchmarking_utils.py`: 
